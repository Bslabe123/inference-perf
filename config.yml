
server:
  vllm:
    base_url: http://0.0.0.0:8000
    load:
      api:
        type: completion
        streaming: false
      type: constant
      stages:
      - rate: 1
        duration: 30
    model:
      name: HuggingFaceTB/SmolLM2-135M-Instruct
      tokenizer:
        trust_remote_code: true
data:
  type: shareGPT
metrics:
  type: prometheus
  prometheus:
    url: http://localhost:9090
    scrape_interval: 15
report:
  request_lifecycle:
    summary: true
    per_stage: true
    per_request: false